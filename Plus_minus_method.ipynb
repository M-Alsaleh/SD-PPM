{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb584d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b600bfa-e908-4506-bf49-247c09ffd577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: The Plus Minus Method analysis.\n",
    "#You will need the survey data to run this part of the code. The data can be requested from Geoscience Australia through https://dx.doi.org/10.26186/146309."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a70a52b-3e6d-47de-8b38-891cf290932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #Only needed for the first part of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573fb2da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Part 1.1\n",
    "#All files\n",
    "files = ['74-WAB', '74-WAC', '76-WBA', '79-WDA', '79-WDB', '79-WDF', '79-WDG', '80-WFJ', '80-WFW', '80-WGE', '80-WGG-WGT', '80-WGK-82-WLN', '80-WGN', '80-WGS', '80-WHR', '82-QNB', '82-RAP', '82-RAR2', '82-RAX', '82-WLA', '82-WLE', '84-TZH', '84-TZJ', '84-TZL', '84-TZM', '84-TZP', '84-TZW', '84-TZX', '84-TZZ', '84-WMD', '84-WME', '84-WMJ', '84-WML', '84-WMM', '84-WMQ', '84-WMT', '84-WMX', '84-WMZ', '84-WNA', '84-XAA', '84-XAB', '84-XAF', '84-XAH', '84-XEZ', '84-XFG', '85-WPC', '85-WPD', '85-WPF', '85-WPY', '85-YGN', '85-YGS', '85-YGW', '85-YRS', '86-ADS', '86-AEB', '86-AED', '86-AEY', '87-WRA', '87NT-05', '87NT-07', '87NT-12', '87NT-19', '88-WRF', '88-WRH', '88-WRJ', '88-WRK', '94ET-05', '94ET-06', 'CB08-01', 'CMA08-09', 'CV08-05', 'CVM08-10', 'NT-01', 'S85C-06', 'S85C-09', 'S86MT-01A-01B', 'S87-SI-05', 'SD79-16', 'SD84-101', 'SD84-44', 'SD84-45', 'SD85-51', 'SD85-60','85-YRZ']\n",
    "#'82-QNE' doesn't contain useful stations\n",
    "for file in files:\n",
    "    print(\"-working on file %s\"%file)\n",
    "    file0 = open('Picks/%s_pick.txt'%file, 'r')\n",
    "    lines = file0.readlines()\n",
    "    df0 = []\n",
    "    for line in lines[2:]:\n",
    "        values = re.split(r'\\s+', line.strip())\n",
    "        df0.append(np.asarray(values, dtype='float'))\n",
    "    df0 = np.stack(df0)\n",
    "    dfpick  = pd.DataFrame(df0,columns=['ffid','sou_pos','srf_pos','chan','fb_pick'])\n",
    "    #ffid: Shot ID, sou_pos: Source poisition (Station number), srf_pos: Reciever position (Station number), Chan: Recording channel, \n",
    "    #fb_pick: Picked time of the first p-wave arriving to the recoding station.  \n",
    "    \n",
    "    #dfpick.to_csv('Picks/%s_pick.csv' % file, index=False)\n",
    "    \n",
    "    file1 = open('RPS/%s.RPS'%file, 'r')\n",
    "    lines = file1.readlines()\n",
    "    df1   = []\n",
    "    for line in lines[25:]:\n",
    "        temp = re.split('\\s+', line)[1:11]\n",
    "        df1.append(np.asarray([temp[0],temp[3], temp[5], temp[6], temp[7]], dtype=float))\n",
    "    df1 = np.stack(df1)\n",
    "    dfRPS  = pd.DataFrame(df1,columns=['STATION','DATUM','EASTING','NORTHING','S_ELEVATION'])\n",
    "    #STATION: Station number, DATUM: static correction datum, EASTING, NORTHING, S_ELEVATION: Station Elevation ASL. \n",
    "    \n",
    "    print(\"-- file %s : dataframe ceated, now merging data\"%file)\n",
    "    \n",
    "    # Joining the DataFrames based on 'sou_pos' and 'STATION'\n",
    "    df_merged_sou = pd.merge(dfpick, dfRPS, left_on='sou_pos', right_on='STATION', how='left')\n",
    "\n",
    "    # Renaming the columns\n",
    "    df_merged_sou = df_merged_sou.rename(columns={'EASTING': 'S_X', 'NORTHING': 'S_Y', 'S_ELEVATION': 'S_Z'})\n",
    "\n",
    "    # Joining the DataFrames based on 'srf_pos' and 'STATION'\n",
    "    df_merged_srf = pd.merge(dfpick, dfRPS, left_on='srf_pos', right_on='STATION', how='left')\n",
    "\n",
    "    # Renaming the columns\n",
    "    df_merged_srf = df_merged_srf.rename(columns={'EASTING': 'R_X', 'NORTHING': 'R_Y', 'S_ELEVATION': 'R_Z'})\n",
    "\n",
    "    # Selecting the desired columns\n",
    "    df = dfpick[['sou_pos', 'srf_pos', 'fb_pick']].copy()\n",
    "\n",
    "    # Adding the columns from df_merged_sou to df\n",
    "    df[['S_X', 'S_Y', 'S_Z']] = df_merged_sou[['S_X', 'S_Y', 'S_Z']]\n",
    "\n",
    "    # Adding the columns from df_merged_srf to df\n",
    "    df[['R_X', 'R_Y', 'R_Z']] = df_merged_srf[['R_X', 'R_Y', 'R_Z']]\n",
    "    print(\"--- file %s : data merging completed, now assigning picks\"%file)\n",
    "\n",
    "    # Dropping invalid picks\n",
    "    df = df[df['fb_pick'] > 0]\n",
    "\n",
    "    # Source reciever separation (offset)\n",
    "    df['S_R_Separation'] = np.sqrt((df['S_X'] - df['R_X'])**2 + (df['S_Y'] - df['R_Y'])**2)\n",
    "\n",
    "    # Assigning picks according to source-reciever geometry\n",
    "\n",
    "    df['ABCD_t'] = np.where(df['sou_pos'] < df['srf_pos'], df['fb_pick'], -9999.00)\n",
    "    df['GFED_t'] = np.where(df['sou_pos'] > df['srf_pos'], df['fb_pick'], -9999.00)\n",
    "\n",
    "    # Source-reciever geometry labelling\n",
    "    df['S_Geometry'] = np.where(df['ABCD_t'] > 0, 'A', 'G')\n",
    "\n",
    "    # Separating picks according to geometry\n",
    "    stations_A = df[df['S_Geometry'] == 'A']\n",
    "    stations_G = df[df['S_Geometry'] == 'G']\n",
    "\n",
    "    # Cleaning and labelling: Stations_A\n",
    "    stations_A = stations_A.drop('GFED_t', axis=1)\n",
    "    stations_A = stations_A.rename(columns={'S_R_Separation': 'AD_Separation'})\n",
    "    stations_A = stations_A.drop(['fb_pick'], axis=1)\n",
    "\n",
    "    # Cleaning and labelling Stations_G\n",
    "    stations_G = stations_G.drop('ABCD_t', axis=1)\n",
    "    stations_G = stations_G.drop(['R_X','R_Y','R_Z'], axis=1)\n",
    "    stations_G = stations_G.drop(['fb_pick'], axis=1)\n",
    "    stations_G = stations_G.rename(columns={'S_R_Separation': 'GD_Separation'})\n",
    "\n",
    "    # Merging shots based on common reciever station.\n",
    "    df = pd.merge(stations_A, stations_G, on='srf_pos', suffixes=('_A', '_G'))\n",
    "    df = df.drop(['S_Geometry_A','S_Geometry_G'], axis=1)\n",
    "\n",
    "    columns_order = ['srf_pos',\n",
    "     'R_X',\n",
    "     'R_Y',\n",
    "     'R_Z',\n",
    "     'sou_pos_A',\n",
    "     'AD_Separation',\n",
    "     'ABCD_t',\n",
    "     'S_X_A',\n",
    "     'S_Y_A',\n",
    "     'S_Z_A',\n",
    "     'sou_pos_G',\n",
    "     'GD_Separation',\n",
    "     'GFED_t',\n",
    "     'S_X_G',\n",
    "     'S_Y_G',\n",
    "     'S_Z_G',]\n",
    "    df=df[columns_order]\n",
    "    \n",
    "    print(\"--- file %s : picks assigned, now assigning ABFG\"%file)\n",
    "    \n",
    "    # Keeping A and G with similar separation from D\n",
    "    condition = (df['srf_pos'] - df['sou_pos_A']) == (df['sou_pos_G'] - df['srf_pos'])\n",
    "    df = df.loc[condition].reset_index()   \n",
    "    \n",
    "    # Assigning ABFG values from where G was a reciever\n",
    "    for i in range(len(df)):\n",
    "        mask = (df['srf_pos'] == df['sou_pos_G'].iloc[i]) & (df['sou_pos_A'] == df['sou_pos_A'].iloc[i]) \n",
    "        if mask.any():\n",
    "            df.at[i, 'ABFG_t'] = df.loc[mask, 'ABCD_t'].iloc[0]\n",
    "            df.at[i, 'sou_pos_AG'] = df.loc[mask, 'sou_pos_A'].iloc[0]\n",
    "            df.at[i, 'AG_Separation'] = df.loc[mask, 'AD_Separation'].iloc[0]\n",
    "        else:\n",
    "            df.at[i, 'ABFG_t'] = -9999.00\n",
    "\n",
    "    print(\"---- file %s : exporting stations_D\"%file)\n",
    "\n",
    "    #df.to_csv('Stations_D/%s_stations_D.csv' % file, index=False)\n",
    "\n",
    "    df = df.drop(df[df['ABFG_t'] <= 0].index) #Drops false picks\n",
    "    print(\"----- file %s : data processing started\"%file)\n",
    "\n",
    "    #calculating T_plus time in seconds Yilmaz P378 (3 - 47 a)\n",
    "    df['Tplus']=(df['ABCD_t']+df['GFED_t']-df['ABFG_t'])*0.001 \n",
    "    #calculating T_minus time in seconds Yilmaz P378 (3 - 47 b)\n",
    "    df['Tminus']=(df['ABCD_t']-df['GFED_t']+df['ABFG_t'])*0.001 \n",
    "\n",
    "    # Assuming the weathering layer velocity as 800 m/s\n",
    "    Vw = 800 \n",
    "    # Yilmaz P379 (3 - 48 c) solved for calculating Vb (subweathering velocity)\n",
    "    df['Vb']=(2*df['AD_Separation'])/(df['Tminus']-df['Tplus'])  \n",
    "    # Yilmaz P378 (3 - 48 a) solved for Zw (depth to subweathering)\n",
    "    df['Zw'] = (df['Tplus'] * df['Vb'] * Vw) / (2 * np.sqrt(df['Vb']**2 - Vw**2))\n",
    "\n",
    "    #df.to_csv('%s_df_AGD.csv' % file, index=False)\n",
    "\n",
    "    #1: constant station separation\n",
    "    #2 and 3: Avoiding suspected picking issues\n",
    "    #4 and 5: Avoiding subweathering velocities out of the accepted range\n",
    "    # 6-9: avoiding too small or too large source reciever separation\n",
    "    condition1 = (df['Tplus']) > 0\n",
    "    condition2 = (df['Tminus']) > 0\n",
    "    condition3 = (df['Vb'] >= 1600)\n",
    "    condition4 = (df['Vb'] <= 2300)\n",
    "\n",
    "    # Combine the conditions using logical AND\n",
    "    conditions = condition1 & condition2 & condition3 & condition4\n",
    "\n",
    "    # Filter the DataFrame using the conditions\n",
    "    df = df.loc[conditions].reset_index()\n",
    "\n",
    "    print(\"------ file %s : exporting results\"%file)\n",
    "\n",
    "    # Taking the mean of the estimates\n",
    "    df_Zw_means = df.loc[:, ['srf_pos', 'R_X', 'R_Y', 'R_Z', 'Vb', 'Zw']]\n",
    "    df_Zw_means = df_Zw_means.groupby('srf_pos').mean().reset_index()\n",
    "    df_Zw_means['Transect_Distance']  = ((df_Zw_means['R_X']-df_Zw_means['R_X'][0])**2+(df_Zw_means['R_Y']-df_Zw_means['R_Y'][0])**2)**0.5\n",
    "    df_Zw_means.to_csv('Zw_means/%s_df_Zw_means.csv' % file, index=False)\n",
    "\n",
    "    easting = df_Zw_means['R_X']\n",
    "    northing = df_Zw_means['R_Y']\n",
    "    depth = df_Zw_means['Zw']\n",
    "\n",
    "    # Increase the figure size in the x-axis\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Create scatter plot with colormap\n",
    "    scatter = ax.scatter(easting, northing, c=depth, cmap='jet', s=1)\n",
    "\n",
    "    # Add colorbar using the scatter plot as the mappable\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label('Estimated depth (m)')\n",
    "\n",
    "    # Add axis labels and title\n",
    "    ax.set_xlabel('Easting')\n",
    "    ax.set_ylabel('Northing')\n",
    "    ax.set_title('Depth to the base of the weathering layer')\n",
    "\n",
    "    # Disable scientific notation on the y-axis tick labels\n",
    "    formatter = ticker.ScalarFormatter(useOffset=False)\n",
    "    ax.yaxis.set_major_formatter(formatter)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig('Transects_top/Estimated_Depths_%s.png' % file, dpi=300)\n",
    "    # Show the plot\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 8))  # Adjust the figure size as needed\n",
    "    \n",
    "    # Plot surface and bedrock elevation\n",
    "    axs[0].plot(df_Zw_means['Transect_Distance'], df_Zw_means['R_Z'], label='Surface')\n",
    "    axs[0].plot(df_Zw_means['Transect_Distance'], df_Zw_means['R_Z'] - df_Zw_means['Zw'], label='Bedrock')\n",
    "    axs[0].legend()\n",
    "    axs[0].set_xlabel('Along-transect distance (m)')\n",
    "    axs[0].set_ylabel('Elevation ASL (m)')\n",
    "    axs[0].set_xlim(df_Zw_means['Transect_Distance'].min() - 10, df_Zw_means['Transect_Distance'].max() + 10)  # Extend X-axis by 10 units on both sides\n",
    "    \n",
    "    # Plot weathered zone thickness\n",
    "    axs[1].plot(df_Zw_means['Transect_Distance'], df_Zw_means['Zw'], 'r', label='Weathered zone')\n",
    "    axs[1].legend()\n",
    "    axs[1].set_xlabel('Along-transect distance (m)')\n",
    "    axs[1].set_ylabel('Thickness (m)')\n",
    "    axs[1].set_xlim(df_Zw_means['Transect_Distance'].min() - 10, df_Zw_means['Transect_Distance'].max() + 10)  # Extend X-axis by 10 units on both sides\n",
    "    \n",
    "    plt.tight_layout()  # Adjust subplot spacing\n",
    "    \n",
    "    plt.subplots_adjust(top=0.9)  # Increase the top spacing for the title\n",
    "    plt.suptitle('Transect Side', fontsize=16, y=0.98)  # Add the title above the subplots\n",
    "    \n",
    "    plt.savefig('Transects_side/%s_transect_side.png' % file, dpi=300)\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7766579-1d66-4353-80b5-b9bca7ba3b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1.2\n",
    "df_Zw_means = []\n",
    "for file in files:\n",
    "    df = pd.read_csv('Zw_means/%s_df_Zw_means.csv' % file)\n",
    "    df = df.assign(File=file)  # Create a new column 'File' and assign the file name to it\n",
    "    df_Zw_means.append(df)\n",
    "\n",
    "df_Zw_means = pd.concat(df_Zw_means)\n",
    "df_Zw_means.to_csv('Estimated_Depths.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359afe59-aa3d-46d9-9551-da505870184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: reading and plotting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a060f-d6b3-4eff-836b-c8ae5cbfee18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Part 2.1: Reading the results\n",
    "df_Zw_means = pd.read_csv('Estimated_Depths.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320cbbee-29ba-4aab-99de-9ce30d51f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2.2: Map plot\n",
    "\n",
    "# Load the map image\n",
    "map_image = mpimg.imread('map_for_plot.png')\n",
    "\n",
    "# Scatter plot with colormap\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "\n",
    "scatter = ax.scatter(df_Zw_means['R_X'], df_Zw_means['R_Y'], c=df_Zw_means['Zw'], cmap='jet', s=1, vmin=0, vmax=100)\n",
    "\n",
    "x_min = df_Zw_means['R_X'].min() - 3000\n",
    "x_max = df_Zw_means['R_X'].max() + 3000\n",
    "y_min = df_Zw_means['R_Y'].min() - 3000\n",
    "y_max = df_Zw_means['R_Y'].max() + 3000\n",
    "\n",
    "ax.set_xlim(x_min, x_max)\n",
    "ax.set_ylim(y_min, y_max)\n",
    "\n",
    "# Set equal aspect ratio\n",
    "aspect_ratio = abs((x_max - x_min) / (y_max - y_min))\n",
    "ax.set_aspect(aspect_ratio)\n",
    "\n",
    "# Disable scientific notation on the y-axis tick labels\n",
    "formatter = ticker.ScalarFormatter(useOffset=False)\n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "# Set the map image as the background using ax.imshow()\n",
    "ax.imshow(map_image, extent=[x_min, x_max, y_min, y_max])\n",
    "\n",
    "# Colorbar settings\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Zw (m)')\n",
    "\n",
    "# Axis labels and title\n",
    "ax.set_xlabel('Easting')\n",
    "ax.set_ylabel('Northing')\n",
    "ax.set_title('Depth to the Base of the Weathering Layer')\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('Estimated_Depths.png', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed18b12-c942-43ce-b29f-ceb8f95fdfb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Part 2.3.1 Access certain parts of seismic lines\n",
    "srf_pos_min = 2863\n",
    "srf_pos_max = 2887\n",
    "desired_file = 'NT-01'\n",
    "\n",
    "# Filter the data based on the srf_pos range and file name\n",
    "filtered_data = df_Zw_means[(df_Zw_means['srf_pos'] >= srf_pos_min) & (df_Zw_means['srf_pos'] <= srf_pos_max) & (df_Zw_means['File'] == desired_file)]\n",
    "\n",
    "# Check if there is any data matching the filter\n",
    "if filtered_data.empty:\n",
    "    print('No data')\n",
    "else:\n",
    "    # Create the figure and axes\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "    # Plot surface and bedrock elevation\n",
    "    axs[0].plot(filtered_data['Transect_Distance'], filtered_data['R_Z'], label='Surface')\n",
    "    axs[0].plot(filtered_data['Transect_Distance'], filtered_data['R_Z'] - filtered_data['Zw'], label='Bedrock')\n",
    "    axs[0].legend()\n",
    "    axs[0].set_xlabel('Along-transect distance (m)')\n",
    "    axs[0].set_ylabel('Elevation ASL (m)')\n",
    "    axs[0].set_xlim(filtered_data['Transect_Distance'].min() - 10, filtered_data['Transect_Distance'].max() + 10)\n",
    "\n",
    "    # Plot weathered zone thickness\n",
    "    axs[1].plot(filtered_data['Transect_Distance'], filtered_data['Zw'], 'r', label='Weathered zone')\n",
    "    axs[1].legend()\n",
    "    axs[1].set_xlabel('Along-transect distance (m)')\n",
    "    axs[1].set_ylabel('Thickness (m)')\n",
    "    axs[1].set_xlim(filtered_data['Transect_Distance'].min() - 10, filtered_data['Transect_Distance'].max() + 10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.suptitle('Transect Side: Part of the transect', fontsize=16, y=0.98)\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig('%s_transect_side_partial.png' % desired_file, dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e4452-3127-4a1a-b26d-d15ee3fe6e25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Part 2.3.2 Examples plot\n",
    "# Define the desired srf_pos range and file name for the first plot\n",
    "srf_pos_min_1 = 2863\n",
    "srf_pos_max_1 = 2887\n",
    "desired_file_1 = 'NT-01'\n",
    "\n",
    "# Filter the data for the first plot\n",
    "filtered_data_1 = df_Zw_means[(df_Zw_means['srf_pos'] >= srf_pos_min_1) & (df_Zw_means['srf_pos'] <= srf_pos_max_1) & (df_Zw_means['File'] == desired_file_1)]\n",
    "\n",
    "# Define the desired srf_pos range and file name for the second plot\n",
    "srf_pos_min_2 = 1211\n",
    "srf_pos_max_2 = 1235\n",
    "desired_file_2 = 'CV08-05'\n",
    "\n",
    "# Filter the data for the second plot\n",
    "filtered_data_2 = df_Zw_means[(df_Zw_means['srf_pos'] >= srf_pos_min_2) & (df_Zw_means['srf_pos'] <= srf_pos_max_2) & (df_Zw_means['File'] == desired_file_2)]\n",
    "\n",
    "# Check if there is any data matching the filter for each plot\n",
    "if filtered_data_1.empty:\n",
    "    print('No data - file1')\n",
    "elif filtered_data_2.empty:\n",
    "    print('No data - file 2')\n",
    "else:\n",
    "    # Create the figure and axes for the subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Settings for the first plot\n",
    "    ax1 = axs[0]\n",
    "    ax1.plot(filtered_data_1['Transect_Distance'], filtered_data_1['R_Z'], label='Surface')\n",
    "    ax1.plot(filtered_data_1['Transect_Distance'], filtered_data_1['R_Z'] - filtered_data_1['Zw'], label='Bedrock')\n",
    "    ax1.legend(loc= 'center right')\n",
    "    ax1.set_xlabel('Along-transect distance (m)')\n",
    "    ax1.set_ylabel('Elevation ASL (m)')\n",
    "    ax1.set_xlim(filtered_data_1['Transect_Distance'].min() - 10, filtered_data_1['Transect_Distance'].max() + 10)\n",
    "    ax1.set_title('Transect Side: Across a Dune Strike')  \n",
    "    # Print coordinates\n",
    "    ax1.plot(filtered_data_1['Transect_Distance'].iloc[[0, -1]], filtered_data_1['R_Z'].iloc[[0, -1]], 'kx', markersize=5)\n",
    "    ax1.text(filtered_data_1['Transect_Distance'].iloc[0], filtered_data_1['R_Z'].iloc[0], f\"{filtered_data_1['R_X'].iloc[0]}, {filtered_data_1['R_Y'].iloc[0]}\", ha='left', va='bottom', fontsize=8)\n",
    "    ax1.text(filtered_data_1['Transect_Distance'].iloc[-1], filtered_data_1['R_Z'].iloc[-1], f\"{filtered_data_1['R_X'].iloc[-1]}, {filtered_data_1['R_Y'].iloc[-1]}\", ha='right', va='top', fontsize=8)\n",
    "\n",
    "    # Settings for the second plot\n",
    "    ax2 = axs[1]\n",
    "    ax2.plot(filtered_data_2['Transect_Distance'], filtered_data_2['R_Z'], label='Surface')\n",
    "    ax2.plot(filtered_data_2['Transect_Distance'], filtered_data_2['R_Z'] - filtered_data_2['Zw'], label='Bedrock')\n",
    "    ax2.legend(loc= 'center right')\n",
    "    ax2.set_xlabel('Along-transect distance (m)')\n",
    "    ax2.set_ylabel('Elevation ASL (m)')\n",
    "    ax2.set_xlim(filtered_data_2['Transect_Distance'].min() - 10, filtered_data_2['Transect_Distance'].max() + 10)\n",
    "    ax2.set_title('Transect Side: Along a Dune Strike')\n",
    "    # Print coordinates \n",
    "    ax2.plot(filtered_data_2['Transect_Distance'].iloc[[0, -1]], filtered_data_2['R_Z'].iloc[[0, -1]], 'kx', markersize=5)\n",
    "    ax2.text(filtered_data_2['Transect_Distance'].iloc[0], filtered_data_2['R_Z'].iloc[0], f\"{filtered_data_2['R_X'].iloc[0]}, {filtered_data_2['R_Y'].iloc[0]}\", ha='left', va='bottom', fontsize=8)\n",
    "    ax2.text(filtered_data_2['Transect_Distance'].iloc[-1], filtered_data_2['R_Z'].iloc[-1], f\"{filtered_data_2['R_X'].iloc[-1]}, {filtered_data_2['R_Y'].iloc[-1]}\", ha='right', va='top', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig('transect_panel.png', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21542f1-dbbe-4c4d-984c-13b2d1773ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Part 2.4 Zw histogram\n",
    "plt.hist(df_Zw_means['Zw'], bins=50,log=True)  # 'bins' parameter sets the number of bins in the histogram\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Zw')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Depths Histogram')\n",
    "\n",
    "#Saving the histogram figure\n",
    "plt.savefig('histogram.png', dpi=300)\n",
    "\n",
    "# Displaying the histogram\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e582e-bc39-4879-b95e-78a806d435e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Part 2.5: Zw and Vb averages\n",
    "\n",
    "df_Zw_means['Zw'].mean(), df_Zw_means['Vb'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72bad9-1397-483b-8797-d3707163804a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Part 2.6 The plus minus method diagram\n",
    "\n",
    "# Define the coordinates of the stations and points\n",
    "A = (0, 0)\n",
    "D = (150, 0)\n",
    "G = (300, 0)\n",
    "B = (30, -20)\n",
    "C = (120, -20)\n",
    "E = (180, -20)\n",
    "F = (270, -20)\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "\n",
    "# Set up the axes for ABCD raypath subplot\n",
    "ax.set_xlim(-10, 310)\n",
    "ax.set_ylim(-22.5, 8)\n",
    "\n",
    "# Draw the surface and refractor lines for ABCD raypath\n",
    "ax.axhline(y=0, color='black', linestyle='--', label='Surface')\n",
    "ax.axhline(y=-20, color='black', linestyle='-', label='Refractor')\n",
    "\n",
    "# Draw a vertical line from point D to the refractor with dash-dot line style\n",
    "ax.plot([D[0], D[0]], [D[1], -20], linestyle='-.', color='black', label='Zw')\n",
    "\n",
    "# Plot line 1 extending from A to B, B to C, and C to D for ABCD raypath\n",
    "ax.plot([A[0], B[0], C[0], D[0]], [A[1], B[1], C[1], D[1]], 'r-', label='ABCD raypath')\n",
    "ax.plot([G[0], F[0], E[0], D[0]], [G[1], F[1], E[1], D[1]], 'b-', label='GFED raypath')\n",
    "ax.plot([A[0], B[0], F[0], G[0]], [A[1], B[1], F[1], G[1]], 'yellow', linestyle='dashdot', label='ABFG raypath')\n",
    "\n",
    "# Add labels for the points in ABCD raypath subplot\n",
    "ax.text(*A, 'A', ha='center', va='bottom', fontsize=12)\n",
    "ax.text(*D, 'D', ha='center', va='bottom', fontsize=12)\n",
    "ax.text(*G, 'G', ha='center', va='bottom', fontsize=12)\n",
    "ax.text(*B, 'B', ha='center', va='top', fontsize=12)\n",
    "ax.text(*C, 'C', ha='center', va='top', fontsize=12)\n",
    "ax.text(*E, 'E', ha='center', va='top', fontsize=12)\n",
    "ax.text(*F, 'F', ha='center', va='top', fontsize=12)\n",
    "\n",
    "# Remove ticks and labels for x and y axes\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "#legends settings\n",
    "ax.legend(loc='upper right', fontsize=12, frameon=False, shadow=True,  ncol=3)\n",
    "\n",
    "# Set the title\n",
    "ax.set_title('The Plus Minus Method', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('The_Plus_Minus_Method_Single_Panel.png', dpi=300)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
